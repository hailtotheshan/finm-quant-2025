{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f212fc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Haotian Lan\n",
    "Copilot is used for only debugging in this assignment.\n",
    "No code in this assignment is copied directly from copilot unless explicitly outlined in comments\n",
    "This is my answer to Homework 1 in FINM 25000\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15df6309",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6290fb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Import the data from 'hedge_fund_series' sheet in the excel file given\n",
    "    hedge_fund_series = pd.read_excel(\"proshares_analysis_data.xlsx\",\n",
    "                                      sheet_name='hedge_fund_series', header=0, index_col=0)\n",
    "    # print(hedge_fund_series)\n",
    "\n",
    "    print(\"\\n1.For the series in the \\\"hedge fund series\\\" tab, \"\n",
    "          \"report the following summary statistics:\")\n",
    "    print('''- mean \n",
    "- volatility\n",
    "- Sharpe ratio\n",
    "- Annualize these statistics.''')\n",
    "\n",
    "    summary_statistics = pd.DataFrame({\n",
    "        'Annualized Mean': hedge_fund_series.mean() * 12,\n",
    "        'Annualized Volatility': hedge_fund_series.std() * np.sqrt(12),\n",
    "        'Annualized Sharpe ratio': (hedge_fund_series.mean() * 12) / (hedge_fund_series.std() * np.sqrt(12))\n",
    "    })\n",
    "    print(\"\\n\", summary_statistics)\n",
    "\n",
    "    print('''\\n2. For the series in the \"hedge fund series\" tab, calculate the following statistics related to tail-risk.\n",
    "- Skewness\n",
    "- Excess Kurtosis (in excess of 3)\n",
    "- VaR (.05) - the fifth quantile of historic returns\n",
    "- CVaR (.05) - the mean of the returns at or below the fifth quantile\n",
    "- Maximum drawdown - include the dates of the max/min/recovery within the max drawdown period.\n",
    "There is no need to annualize any of these statistics.''')\n",
    "\n",
    "    risk = pd.DataFrame({\n",
    "        # Compute and print out skewness and kurtosis\n",
    "        'Skewness': hedge_fund_series.skew(),\n",
    "        'Kurtosis': hedge_fund_series.kurt(),\n",
    "        # Compute and print out VaR (.05) and CVaR (.05)\n",
    "        # VaR (.05) = the fifth quantile of historic returns\n",
    "        'VaR(.05)': hedge_fund_series.quantile(0.05),\n",
    "        # CVaR (.05) = the mean of the returns at or below the fifth quantile\n",
    "        'CVaR(.05)': hedge_fund_series[hedge_fund_series <= hedge_fund_series.quantile(0.05)].mean(),\n",
    "        'Maximum Drawdown': cal_drawdown(hedge_fund_series),\n",
    "    })\n",
    "    print(\"\\n\", risk)\n",
    "\n",
    "    print(\"\"\"\\n3.\n",
    "For the series in the \"hedge fund series\" tab, run a regression of each against SPY (found in the \"merrill factors\" tab.) \n",
    "Include an intercept. Report the following regression-based statistics:\n",
    "- Market Beta\n",
    "- Treynor Ratio\n",
    "- Information ratio\n",
    "Annualize these three statistics as appropriate.\"\"\")\n",
    "\n",
    "    # Import the data from 'merrill_factors' sheet in the excel file given\n",
    "    merrill_factors = pd.read_excel(\"proshares_analysis_data.xlsx\",\n",
    "                                    sheet_name='merrill_factors', header=0, index_col=0)\n",
    "    # Combine data from hedge_fund_series and merill_factors by date\n",
    "    combined_data = hedge_fund_series.join(merrill_factors[['SPY US Equity']], how='inner')\n",
    "\n",
    "    # Compute betas of funds using calculate_beta function\n",
    "    market_beta = calculate_beta(combined_data, 'SPY US Equity')\n",
    "\n",
    "    treynor = {}\n",
    "    # Treynor ratio = r_i / beta\n",
    "    for hedge_fund, beta_value in market_beta.items():\n",
    "        # Annualize return by a scale of 12\n",
    "        treynor_ratio = combined_data[hedge_fund].mean() * 12 / beta_value\n",
    "        # print(f\"{hedge_fund}: {treynor_ratio:.4f}\")\n",
    "        treynor[hedge_fund] = treynor_ratio\n",
    "\n",
    "    information = {}\n",
    "    # This block about calculating information ratios is directly written by Copilot\n",
    "    # print(\"\\nInformation ratio:\")\n",
    "    for hedge_fund in hedge_fund_series:\n",
    "        # For a given fund column 'FundX'\n",
    "        y = combined_data[hedge_fund]\n",
    "        X = combined_data['SPY US Equity']\n",
    "        X = sm.add_constant(X)  # Add intercept\n",
    "\n",
    "        # Run the OLS regression: r_fund = alpha + beta*r_market + error\n",
    "        model = sm.OLS(y, X).fit()\n",
    "\n",
    "        # Extract Regession Parameters\n",
    "        alpha = model.params['const']\n",
    "        beta = model.params['SPY US Equity']\n",
    "        # print(\"Alpha:\", round(alpha, 4), \"Beta:\", round(beta, 4))\n",
    "\n",
    "        # Calculate residuals (tracking errors) from the regression\n",
    "        residuals = model.resid\n",
    "\n",
    "        # Compute the standard deviation (tracking error) of the residuals (monthly)\n",
    "        tracking_error = np.std(residuals, ddof=1)\n",
    "\n",
    "        # Annualize the monthly alpha and tracking error:\n",
    "        annualized_alpha = alpha * 12\n",
    "        annualized_tracking_error = tracking_error * np.sqrt(12)\n",
    "\n",
    "        # Compute the annualized information ratio\n",
    "        information_ratio = annualized_alpha / annualized_tracking_error\n",
    "\n",
    "        # print(f\"{hedge_fund}:\", round(information_ratio, 4))\n",
    "        information[hedge_fund] = information_ratio\n",
    "    # Direct copy of Copilot ends in this line\n",
    "\n",
    "    # Combine three dictionaries into one dataframe\n",
    "    factor_decomposition = pd.DataFrame({\n",
    "        'Market Beta': pd.Series(market_beta),\n",
    "        'Treynor Ratio': pd.Series(treynor),\n",
    "        'Information Ratio': pd.Series(information)})\n",
    "\n",
    "    print(\"\\nFactor Decomposition:\")\n",
    "    print(factor_decomposition)\n",
    "\n",
    "    print(\"\"\"\\n4.\n",
    "Discuss the previous statistics, and what they tell us about...\n",
    "\n",
    "- the differences between SPY and the hedge-fund series?\n",
    "- which performs better between HDG and QAI.\n",
    "- whether HDG and the ML series capture the most notable properties of HFRI.\"\"\")\n",
    "    print(\"\"\"  Since the all four funds in the hedge_fund_series have a market beta less than 1,\n",
    "the funds are less aligned to the equity market overall fluctuation and exposed to less systematic risks.\n",
    "The Treynors ratios of hedge_fund series are below the ratio of SPY. This indicates either hedge_fund\n",
    "did not earn enough return when bearing same amount of risk as the market or hedge funds are exposed to \n",
    "more risks when they earned the same amount of return as the market.\n",
    "All funds have a negative information ratio, signifying a relatively large amount of noise in its return.\n",
    "  QAI performed better than HDG because QAI has less market beta, higher treynor ratio, and higher information ratio.\n",
    "This reveals QAI was less aligned with market fluctuation, earned a higher risk-adjusted return, and had less\n",
    "noise in its alpha.\n",
    "  While HDG and ML series have low beta, they still had large drawdown, \n",
    "low treynor ratios, and negative information ratios.\"\"\")\n",
    "\n",
    "    print(\"\"\"\\n5.\n",
    "Report the correlation matrix for these assets.\n",
    "\n",
    "- Show the correlations as a heat map.\n",
    "- Which series have the highest and lowest correlations?\"\"\")\n",
    "\n",
    "    # Run the next line of code to generate heatmap\n",
    "    # draw_heatmap(hedge_fund_series, \"Hedge Funds Series vs. SPY\")\n",
    "    print(\"\\nBased on the results shown on the heatmap, MLEIFCTR Index and MLEIFCTX Index\"\n",
    "          \"have the highest correlation of 1.\"\n",
    "          \"\\nMLEIFCTR Index and QAI US Equity have the lowest correlation of 0.89\")\n",
    "\n",
    "    print(\"\"\"\\n6.\n",
    "Replicate HFRI with the six factors listed on the \"merrill factors\" tab. \n",
    "Include a constant, and run the unrestricted regression\n",
    "a. Report the intercept and betas.\n",
    "\n",
    "b. Are the betas realistic position sizes, or do they require huge long-short positions?\n",
    "\n",
    "c. Report the R-squared.\n",
    "\n",
    "d. Report the volatility of Ïµ^merr, the tracking error.\"\"\")\n",
    "\n",
    "    for factor in merrill_factors:\n",
    "        print(f\"\\nRegressions with {factor} as the market benchmark:\")\n",
    "        print(hf_regression(hedge_fund_series, merrill_factors[[factor]]))\n",
    "\n",
    "    print(\"\"\"\\nUSGG3M Index and EUO US Equity with approximately 0 beta does not need much hedging.\n",
    "EUO US Equity with negative beta of -0.41 might require a long-hold position of SPY to mitigate market risk exposure.\n",
    "However, the other equities, including EEM US Equity, EFA US Equity, and IWM US Equity \n",
    "have relatively high beta ranging from 0.8 to 1.2. This indicates a moderate long-short positions:\n",
    "holding these equity might require long-short 80% to 120% of weights in SPY.\"\"\")\n",
    "\n",
    "    print(\"\\n7. Let's examine the replication out-of-sample (OOS).\")\n",
    "\n",
    "    window = 60\n",
    "    dates_oos = []\n",
    "    oos_pred = {f: [] for f in hedge_fund_series.columns}\n",
    "    oos_true = {f: [] for f in hedge_fund_series.columns}\n",
    "\n",
    "    for i in range(window, len(hedge_fund_series)):\n",
    "        date_t = hedge_fund_series.index[i]\n",
    "        dates_oos.append(date_t)\n",
    "\n",
    "        for fund in hedge_fund_series.columns:\n",
    "            y_train = hedge_fund_series[fund].iloc[i - window:i]\n",
    "            X_train = sm.add_constant(merrill_factors['SPY US Equity'].iloc[i - window:i])\n",
    "            model = sm.OLS(y_train, X_train).fit()\n",
    "\n",
    "            alpha = model.params['const']\n",
    "            beta = model.params['SPY US Equity']\n",
    "\n",
    "            x_t = merrill_factors['SPY US Equity'].iloc[i]\n",
    "            y_hat = alpha + beta * x_t\n",
    "\n",
    "            oos_pred[fund].append(y_hat)\n",
    "            oos_true[fund].append(hedge_fund_series[fund].iloc[i])\n",
    "\n",
    "    # Calculate error DataFrames\n",
    "    pred_df = pd.DataFrame(oos_pred, index=dates_oos)\n",
    "    true_df = pd.DataFrame(oos_true, index=dates_oos)\n",
    "    err_df = true_df - pred_df\n",
    "\n",
    "    perf = pd.DataFrame(index=hedge_fund_series.columns)\n",
    "\n",
    "    # Compute performance metrics:\n",
    "    perf['OOS MSE'] = (err_df ** 2).mean()\n",
    "    perf['OOS Corr'] = true_df.corrwith(pred_df)\n",
    "\n",
    "    sse = (err_df ** 2).sum()\n",
    "    sst = ((true_df - true_df.mean()) ** 2).sum()\n",
    "    perf['OOS R2'] = 1 - sse / sst\n",
    "\n",
    "    perf['Mean Error'] = err_df.mean()\n",
    "\n",
    "    print(perf.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbdb2425",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hf_regression(hedge_fund_series, market_df):\n",
    "    \"\"\"The function \"regression_statistics\" is needed for this function.\n",
    "    Input: hedge_fund_series is a df with each column of funds to be compared\n",
    "    with the market by regression\n",
    "    market_df is a single column df of market benchmark to be compared with.\n",
    "    Output: A dataframe has four columns: alpha, beta, R-squared, tracking error.\n",
    "    It has rows of funds corresponding to funds in hedge_fund_series.\"\"\"\n",
    "\n",
    "    # Initialize dictionaries to be compiled into a dataframe as the output\n",
    "    hf_alpha = {}\n",
    "    hf_beta = {}\n",
    "    hf_r2 = {}\n",
    "    hf_error = {}\n",
    "\n",
    "    for hedge_fund in hedge_fund_series:\n",
    "        # Combine hedge_fund_series with market_df\n",
    "        combined_data = hedge_fund_series.join(market_df, how='inner')\n",
    "\n",
    "        # Calculate regression statistics of a column of funds\n",
    "        hedge_fund, annualized_alpha, beta, r2, annualized_tracking_error = (\n",
    "            regression_statistics(combined_data, hedge_fund, market_df.columns))\n",
    "\n",
    "        # Append the regression statistics to the dictionaries\n",
    "        hf_alpha[hedge_fund] = annualized_alpha\n",
    "        hf_beta[hedge_fund] = beta\n",
    "        hf_r2[hedge_fund] = r2\n",
    "        hf_error[hedge_fund] = annualized_tracking_error\n",
    "\n",
    "    # Combine all dictionaries into a single dataframe\n",
    "    hf_factors = pd.DataFrame({\n",
    "        'Alpha': pd.Series(hf_alpha),\n",
    "        'Beta': pd.Series(hf_beta),\n",
    "        'R^2': pd.Series(hf_r2),\n",
    "        'Tracking Error': pd.Series(hf_error)\n",
    "    })\n",
    "\n",
    "    return hf_factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f6af91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_statistics(df, factor, market_column):\n",
    "    \"\"\"Inputs: df is a dataframe containing monthly return of factor and market_column\n",
    "    factor is the columns in the df dataframe to be compared to the market.\n",
    "    market_column is the string name of the market column in df.\n",
    "    Outputs: alpha, beta, R-squared, and epsilon (tracking error) of factor\n",
    "    with respect to the market.\"\"\"\n",
    "\n",
    "    # Y-axis = monthly returns of a factor\n",
    "    y = df[factor]\n",
    "    # X-axis = monthly returns of SPY\n",
    "    X = df[market_column]\n",
    "    X = sm.add_constant(X)  # Add intercept\n",
    "    model = sm.OLS(y, X).fit()\n",
    "\n",
    "    # Calculate the regression statistics of alpha, beta, and R^2\n",
    "    alpha = model.params['const']\n",
    "    beta = model.params[market_column]\n",
    "    r2 = model.rsquared\n",
    "\n",
    "    # Compute tracking errors\n",
    "    residuals = model.resid\n",
    "    # Compute the standard deviation of tracking errors\n",
    "    tracking_error = residuals.std()\n",
    "\n",
    "    # Annualize alpha and tracking error by scale of 12 and sqrt(12)\n",
    "    annualized_alpha = alpha * 12\n",
    "    annualized_tracking_error = tracking_error * np.sqrt(12)\n",
    "\n",
    "    return factor, annualized_alpha, beta, r2, annualized_tracking_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1010ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_heatmap(df, plot_title=\"\"):\n",
    "    # Compute the correlation matrix\n",
    "    correlation_matrix = df.corr()\n",
    "    print(\"Correlation matrix:\\n\", correlation_matrix)\n",
    "\n",
    "    # Plot the correlation matrix as a heatâmap\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\",\n",
    "                cmap=\"coolwarm\", vmin=-1, vmax=1, linewidths=0.5)\n",
    "    plt.title(plot_title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7919ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_beta(df, benchmark):\n",
    "    \"\"\"df is a dataframe containing columns of funds and a market benchmark.\n",
    "    df has row index in datetime with each row value as monthly return.\n",
    "    benchmark is the column name (in strings) of market benchmark to be compared.\n",
    "    The function returns betas of each fund in a dictionary\"\"\"\n",
    "    fund_betas = {}\n",
    "\n",
    "    # Compute the covariance matrix and variance of spy returns in combined data\n",
    "    cov_matrix = np.cov(df[benchmark], df[benchmark])\n",
    "    variance_spy = cov_matrix[0, 0]\n",
    "\n",
    "    # Loop through each hedge fund column except the benchmark column\n",
    "    for hedge_fund in df.columns:\n",
    "        # Compute the covariance between the hedge fund and market benchmark returns.\n",
    "        cov_matrix = np.cov(df[hedge_fund], df[benchmark])\n",
    "        cov_value = cov_matrix[0, 1]\n",
    "\n",
    "        # Market beta = covariance(r_i, r_m) / variance(r_m)\n",
    "        beta = cov_value / variance_spy\n",
    "        # print(f\"{hedge_fund}: {beta:.4f}\"\n",
    "        fund_betas[hedge_fund] = beta\n",
    "\n",
    "    return fund_betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749af2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_drawdown(funds_data):\n",
    "    drawdowns = {}\n",
    "\n",
    "    # normalize the data by dividing all values by the first row\n",
    "    normalized_data = funds_data / funds_data.iloc[0]\n",
    "\n",
    "    # Outer loop iterates over each hedge fund\n",
    "    for hedge_fund in normalized_data.columns:\n",
    "        max_drawdown = 0\n",
    "        running_maximum = 0\n",
    "\n",
    "        # Inner loop iterates over each monthly_return in the current column\n",
    "        for monthly_return in normalized_data[hedge_fund]:\n",
    "            # Update the running maximum so far.\n",
    "            running_maximum = max(running_maximum, monthly_return)\n",
    "            percentage_drawdown = (monthly_return - running_maximum) / running_maximum\n",
    "\n",
    "            # Update maximum drawdown\n",
    "            max_drawdown = min(max_drawdown, percentage_drawdown)\n",
    "        drawdowns[hedge_fund] = max_drawdown\n",
    "\n",
    "    return drawdowns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55a83b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
