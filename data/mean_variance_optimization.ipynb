{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f900d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Haotian Lan\n",
    "Copilot is used for only debugging in this assignment.\n",
    "No code in this assignment is copied directly from copilot.\n",
    "This is my answer to Homework 1 in FINM 25000\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee9a783",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1400fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Import the data from 'excess return' sheet in the excel file given\n",
    "    # The sheet name in the original excel file is changed from 'excess return' to 'excess_return so that I can import it.'\n",
    "    etf_data = pd.read_excel(\"multi_asset_etf_data.xlsx\",\n",
    "                             sheet_name='excess_return', header=0, index_col=0)\n",
    "\n",
    "    print(\"\\n1. Summary Statistics\"\n",
    "          \"\\nCalculate and display the mean and volatility of each asset’s excess return. \"\n",
    "          \"\\n(Recall we use volatility to refer to standard deviation.)\")\n",
    "\n",
    "    # Calculate the mean and the standard deviation for each column in etf_data\n",
    "    etf_means = etf_data.mean() * 12  # mean is scaled by 12\n",
    "    etf_std = etf_data.std() * np.sqrt(12)  # vol is scaled by sqrt(12)\n",
    "\n",
    "    # Merge the means and volatility into a single dataframe\n",
    "    summary = pd.DataFrame([etf_means, etf_std], index=['Mean', 'Standard Deviation'])\n",
    "    summary = summary.T\n",
    "\n",
    "    # Sharpe ratio = mean/standard deviation\n",
    "    summary['Sharpe'] = summary['Mean'] / summary['Standard Deviation']\n",
    "    print(summary)\n",
    "\n",
    "    print(\"\\nWhich assets have the best and worst Sharpe ratios? \"\n",
    "          \"\\nRecall that the Sharpe Ratio is simply the ratio of the mean-to-volatility of excess returns:\")\n",
    "\n",
    "    # Find the maximum and minimum Sharpe ratio\n",
    "    max_sharpe = summary['Sharpe'].max()\n",
    "    min_sharpe = summary['Sharpe'].min()\n",
    "\n",
    "    # Find the ETF with maximum Sharpe ratio and the ETF with minimum Sharpe ratio\n",
    "    max_etf = summary['Sharpe'].idxmax()\n",
    "    min_etf = summary['Sharpe'].idxmin()\n",
    "\n",
    "    print(f\"{max_etf} has the highest Sharpe ratio of {max_sharpe}\")\n",
    "    print(f\"{min_etf} has the lowest Sharpe ratio of {min_sharpe}\")\n",
    "\n",
    "    print(\"\\n2. Descriptive Analysis\"\n",
    "          \"\\nCalculate the correlation matrix of the returns. Which pair has the highest correlation? And the lowest?\")\n",
    "\n",
    "    # Compute the correlation matrix of the given etf data\n",
    "    etf_covariance = etf_data.cov()\n",
    "    print(\"\\nThe etf correlation matrix is as follow:\\n\", etf_covariance)\n",
    "\n",
    "    print(\"\\nHow well have TIPS done in our sample? \"\n",
    "          \"\\nHave they outperformed domestic bonds? Foreign bonds?\")\n",
    "\n",
    "    # Get the mean, std, and sharpe of TIPS in the summary dataframe\n",
    "    tip_mean = summary.loc[\"TIP\", ['Mean']].values\n",
    "    tip_sd = summary.loc[\"TIP\", ['Standard Deviation']].values\n",
    "    tip_sharpe = summary.loc[\"TIP\", ['Sharpe']].values\n",
    "    print(f\"TIPS in our sample has a mean of {tip_mean}, standard deviaiton \"\n",
    "          f\"of {tip_sd}, and a sharpe ratio of {tip_sharpe}.\")\n",
    "\n",
    "    # Allocate domestic bonds and foreign bonds into separate lists\n",
    "    domestic_bonds = ['IEF', 'HYG']\n",
    "    foreign_bonds = ['BWX']\n",
    "\n",
    "    print(\"Compared to domestic bonds, \")\n",
    "    # Compare sharpe ratio of \"TIPS\" to the sharpe ratios of domestic bonds\n",
    "    for bond in domestic_bonds:\n",
    "        if tip_sharpe > summary.loc[bond, ['Sharpe']].values:\n",
    "            print(f\"TIPS has a higher sharpe ratio than {bond}.\")\n",
    "        else:\n",
    "            print(f\"TIPS has a lower sharpe ratio than {bond}.\")\n",
    "\n",
    "    print(\"Compared to foreign bonds, \")\n",
    "    # Compare sharpe ratio of \"TIPS\" to the sharpe ratios of foreign bonds\n",
    "    for bond in foreign_bonds:\n",
    "        if tip_sharpe > summary.loc[bond, ['Sharpe']].values:\n",
    "            print(f\"TIPS has a higher sharpe ratio than {bond}.\")\n",
    "        else:\n",
    "            print(f\"TIPS has a lower sharpe ratio than {bond}.\")\n",
    "\n",
    "    print(\"\\n3. The MV frontier.\"\n",
    "          \"\\nCompute and display the weights of the tangency portfolios: w^tan.\")\n",
    "\n",
    "    # Find the inverse of the covariance matrix\n",
    "    inverse_covariance = np.linalg.inv(etf_covariance)\n",
    "    # Slice the mean from the previous descriptive analysis\n",
    "    excess_return = summary['Mean']\n",
    "\n",
    "    # Compute the unnormalized tangency portfolio weights\n",
    "    unnormalized_weights = inverse_covariance.dot(excess_return)\n",
    "\n",
    "    # Normalize the weights to ensure weights add up to 1\n",
    "    tangency_weights = unnormalized_weights / np.sum(unnormalized_weights)\n",
    "    weights_df = pd.DataFrame(tangency_weights, index=summary.index, columns=[\"Weight\"])\n",
    "    print(weights_df)\n",
    "\n",
    "    print(\"\\nDoes the ranking of weights align with the ranking of Sharpe ratios?\")\n",
    "\n",
    "    # Rank the values in the 'Weight' column of the weight_df\n",
    "    print(\"The ranking of weights is as follow:\")\n",
    "    weight_rank = pd.DataFrame(weights_df, index=weights_df.index)\n",
    "    weight_rank['Rank'] = weights_df['Weight'].rank(method='min', ascending=False)\n",
    "\n",
    "    # Create a new column 'ETF' from the existing index\n",
    "    weight_rank['ETF'] = weight_rank.index\n",
    "    # Set the 'Rank' column as the new index\n",
    "    weight_rank = weight_rank.set_index('Rank')\n",
    "\n",
    "    # Sort the dataframe by the row index and convert the row index to integers\n",
    "    weight_rank = weight_rank.sort_index()\n",
    "    weight_rank.index = weight_rank.index.astype(int)\n",
    "\n",
    "    print(weight_rank)\n",
    "\n",
    "    print(\"The ranking of sharpe ratio is as follow:\")\n",
    "\n",
    "    # Rank the values in the 'Weight' column of the summary\n",
    "    sharpe = summary[['Sharpe']].copy()\n",
    "    sharpe['Rank'] = sharpe['Sharpe'].rank(method='min', ascending=False)\n",
    "\n",
    "    # Create a new column 'ETF' from the existing index\n",
    "    sharpe['ETF'] = sharpe.index\n",
    "    # Set the 'Rank' column as the new index\n",
    "    sharpe = sharpe.set_index('Rank')\n",
    "\n",
    "    # Sort the dataframe by the row index and convert the row index to integers\n",
    "    sharpe = sharpe.sort_index()\n",
    "    sharpe.index = sharpe.index.astype(int)\n",
    "\n",
    "    print(sharpe)\n",
    "    print(\"Based on the comparison of two rankings, \"\n",
    "          \"the ranking of the weights is not perfectly aligned with the ranking of the sharpe ratio.\")\n",
    "\n",
    "    print(\"\\nCompute the mean, volatility, and Sharpe ratio for the tangency portfolio corresponding to w^tan\")\n",
    "\n",
    "    # Performa matrix multiplication on etf_data and tangency_weights\n",
    "    tangency_portfolio = etf_data.dot(tangency_weights)\n",
    "\n",
    "    # Find mean and standard deviation of the tangency portfolio\n",
    "    tangency_mean = tangency_portfolio.mean() * 12  # Annualized return by scaling of 12\n",
    "    tangency_std = tangency_portfolio.std() * np.sqrt(12)  # Annualized standard deviation by scaling of sqrt(12)\n",
    "\n",
    "    # Assume that sharpe ratio = mean / standard deviation\n",
    "    tangency_sharpe = (tangency_mean / tangency_std)\n",
    "\n",
    "    print(f\"For the tangency portfolio,\"\n",
    "          f\"\\nannualized mean = {tangency_mean}\"\n",
    "          f\"\\nannualized standard deviation = {tangency_std}\"\n",
    "          f\"\\nannualized sharpe ratio = {tangency_sharpe}\")\n",
    "\n",
    "    print(\"\\n4. TIPS\")\n",
    "    print(\"\\nAssess how much the tangency portfolio (and performance) change \"\n",
    "          \"if TIPS are dropped completely from the investment set.\")\n",
    "\n",
    "    # Drop the TIP column in the dataset.\n",
    "    without_tips_data = etf_data.drop(\"TIP\", axis=1)\n",
    "    mv_portfolio(without_tips_data, \"when TIPS are dropped from the investment set\")\n",
    "\n",
    "    # Create a copy of the original dataframe\n",
    "    increased_tip = etf_data.copy()\n",
    "    # Increase every value in the 'TIP' column by 0.0012\n",
    "    increased_tip['TIP'] = increased_tip['TIP'] + 0.0012\n",
    "    mv_portfolio(increased_tip, \"when monthly expected return of TIPS increased by 0.0012\")\n",
    "\n",
    "    print(\"\\n 3. Allocations\")\n",
    "    print(\"\\nContinue with the same data file as the previous section.\"\n",
    "          \"\\nSuppose the investor has a targeted mean excess return (per month) of ~μ^port = 0.01.\")\n",
    "\n",
    "    \"\"\"Use equally-weighted allocation, risk-parity allocation,\n",
    "    and mean-variance allocation to determine portfolio of etf data\"\"\"\n",
    "    ew_portfolio(etf_data, 0.01)\n",
    "    rp_portfolio(etf_data)\n",
    "    mv_portfolio(etf_data)\n",
    "\n",
    "    print(\"\\nMean-variance portfolio has the highest sharpe ratio among the three portfolio. \"\n",
    "          \"\\nAt the same time, mean-variance portfolio bears the highest amount of risk.\"\n",
    "          \"\\nWhile risk-parity has the lowest standard deviation, \"\n",
    "          \"its sharpe ratio is low compared to mean-variance portfolio.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29622bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mv_portfolio(etf_data, description=\"\"):  # mean-variance portfolio\n",
    "    # Compute expected annual returns based on the input data\n",
    "    annual_means = etf_data.mean() * 12  # Scale monthly mean to annual\n",
    "\n",
    "    # Compute the covariance matrix and inverse matrix\n",
    "    cov_matrix = etf_data.cov()\n",
    "    inv_cov_matrix = np.linalg.inv(cov_matrix)\n",
    "\n",
    "    # Compute unnormalized tangency portfolio weights\n",
    "    unnormalized_weights = inv_cov_matrix.dot(annual_means)\n",
    "    # Normalize the weights so they sum to 1\n",
    "    tangency_weights = unnormalized_weights / np.sum(unnormalized_weights)\n",
    "    # Compute the portfolio monthly returns via matrix multiplication\n",
    "    portfolio_returns = etf_data.dot(tangency_weights)\n",
    "\n",
    "    # Annualize the portfolio statistics\n",
    "    annualized_mean = portfolio_returns.mean() * 12\n",
    "    annualized_std = portfolio_returns.std() * np.sqrt(12)\n",
    "    annualized_sharpe = (annualized_mean / annualized_std)\n",
    "\n",
    "    # Print the results with an optional description\n",
    "    print(f\"\\nTangency portfolio results using mean-variance optimization {description}:\")\n",
    "    print(f\"Annualized mean = {annualized_mean}\")\n",
    "    print(f\"Annualized standard deviation = {annualized_std}\")\n",
    "    print(f\"Annualized Sharpe ratio = {annualized_sharpe}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c054cf99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ew_portfolio(etf_data, target_mean, description=\"\"):  # Equally-weighted portfolio\n",
    "    n = etf_data.shape[1]  # number of assets\n",
    "    ew_weights = np.ones(n) / n  # equally weighted portfolio\n",
    "\n",
    "    # Determine the scaling factor to achieve the target monthly mean excess return:\n",
    "    mu = etf_data.mean()  # a Series with asset expected returns (monthly)\n",
    "    portfolio_returns = np.dot(ew_weights, mu)\n",
    "    scale = target_mean / portfolio_returns\n",
    "\n",
    "    # Scale the weights\n",
    "    target_ew_weights = scale * ew_weights\n",
    "\n",
    "    # Compute expected return by scaled weight\n",
    "    target_return = np.dot(etf_data, target_ew_weights)\n",
    "\n",
    "    # Annualize the portfolio statistics\n",
    "    annualized_mean = target_return.mean() * 12\n",
    "    annualized_std = target_return.std() * np.sqrt(12)\n",
    "    annualized_sharpe = (annualized_mean / annualized_std)\n",
    "\n",
    "    # Print the results with an optional description\n",
    "    print(f\"\\nTangency portfolio results using equal-weight optimization with target mean of {target_mean} {description}:\")\n",
    "    print(f\"Annualized mean = {annualized_mean}\")\n",
    "    print(f\"Annualized standard deviation = {annualized_std}\")\n",
    "    print(f\"Annualized Sharpe ratio = {annualized_sharpe}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf26db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rp_portfolio(etf_data):\n",
    "    # Compute variances of each asset\n",
    "    asset_variances = etf_data.var()\n",
    "    rp_weights = 1 / asset_variances  # Weight = 1/variance\n",
    "    # Normalize the weights so that they add up to 1\n",
    "    rp_weights = rp_weights / rp_weights.sum()\n",
    "    # Compute the portfolio monthly returns using the RP weights\n",
    "    portfolio_returns = etf_data.dot(rp_weights)\n",
    "\n",
    "    # Annualize the portfolio statistics:\n",
    "    annualized_mean = portfolio_returns.mean() * 12\n",
    "    annualized_std = portfolio_returns.std() * np.sqrt(12)\n",
    "    annualized_sharpe = annualized_mean / annualized_std\n",
    "\n",
    "    # Print out the results\n",
    "    print(\"\\nTangency portfolio results using equal-weight optimization:\")\n",
    "    print(f\"Annualized Mean: {annualized_mean}\")\n",
    "    print(f\"Annualized Standard Deviation: {annualized_std}\")\n",
    "    print(f\"Annualized Sharpe Ratio: {annualized_sharpe}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f26e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
