{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae7e067",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Haotian Lan\n",
    "Copilot is used for only debugging in this assignment.\n",
    "No code in this assignment is copied directly from copilot unless explicitly outlined in comments\n",
    "This is my answer to Homework 3 in FINM 25000\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed691a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d8f982",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Import the data from 'factors (excess returns)' sheet in the excel file given\n",
    "    factors = pd.read_excel(\"factor_pricing_data.xlsx\",\n",
    "                            sheet_name='factors (excess returns)', header=0, index_col=0)\n",
    "    # print(factors)\n",
    "\n",
    "    print(\"\\nPricing Factors and Assets\\n\")\n",
    "    print(\"\"\"\\n1. The Factors. Calculate their univariate performance statistics:\n",
    " • mean\n",
    " • volatility\n",
    " • Sharpe\n",
    " • VaR(.05)\n",
    "Does each factor have a premium (positive expected excess return)?\"\"\")\n",
    "\n",
    "    # Mean, standard deviation, sharpe ratios, and VaR are annnualized\n",
    "    factors_statistics = pd.DataFrame({\n",
    "        'Mean': factors.mean() * 12,\n",
    "        'Volatility': factors.std() * np.sqrt(12),\n",
    "        'Sharpe ratio': (factors.mean() * 12) / (factors.std() * np.sqrt(12)),\n",
    "        'VaR(.05)': factors.quantile(0.05) * np.sqrt(12)\n",
    "    })\n",
    "    print(\"\\n\", factors_statistics)\n",
    "    print(\"Based on the statistics, all factors have a positive expected return.\")\n",
    "\n",
    "    print(\"\"\"\\nThe factors are constructed in such a way as to reduce correlation between them.\n",
    "Report the correlation matrix across the three factors. Does the construction method succeed\n",
    "in keeping correlations small?\"\"\")\n",
    "\n",
    "    # Compute the correlation matrix\n",
    "    correlation_matrix = factors.corr()\n",
    "    print(\"Correlation matrix:\\n\", correlation_matrix)\n",
    "    print(\"The correlation between market factor, value factor, and size factor range from -0.21 to 0.23.\"\n",
    "          \"\\nThus, construction method has succeed in keeping correlations small.\")\n",
    "\n",
    "    print(\"\"\"\\n 3. Plot the cumulative returns of the factors.\"\"\")\n",
    "\n",
    "    # Find cumulative return of each factor\n",
    "    cumulative_return = (1 + factors).cumprod()\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    cumulative_return.plot(linewidth=1.5, colormap='tab10')\n",
    "\n",
    "    # Plot the cumulative return\n",
    "    plt.title(\"Cumulative Return in Each Factor during 1980–2025\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Return in Percentage\")\n",
    "    plt.legend(title=\"Factors\", loc=\"upper left\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(\"\"\"\\n 4. Test assets.\n",
    "The “assets” tab provides monthly excess return data on various industry stock-portfolios.\n",
    "Denote these as ri, for n = 1,...,12.\n",
    "Calculate the (annualized) univariate statistics from 1.1.\"\"\")\n",
    "\n",
    "    # Import the data from 'portfolios (excess returns)' sheet in the excel file given\n",
    "    portfolios = pd.read_excel(\"factor_pricing_data.xlsx\",\n",
    "                               sheet_name='portfolios (excess returns)', header=0, index_col=0)\n",
    "\n",
    "    # Mean, standard deviation, sharpe ratios, and VaR are annnualized\n",
    "    portfolios_statistics = pd.DataFrame({\n",
    "        'Mean': portfolios.mean() * 12,\n",
    "        'Volatility': portfolios.std() * np.sqrt(12),\n",
    "        'Sharpe ratio': (portfolios.mean() * 12) / (portfolios.std() * np.sqrt(12)),\n",
    "        'VaR(.05)': portfolios.quantile(0.05) * np.sqrt(12)\n",
    "    })\n",
    "    print(\"\\n\", portfolios_statistics)\n",
    "\n",
    "    print(\"\"\"\\n 5. Can the difference in mean excess returns of the portfolios be explained by differences in their\n",
    "volatilities? Or by their VaR(.05) statistics?\"\"\")\n",
    "\n",
    "    # mean → X, volatility → Y\n",
    "    x = portfolios_statistics.iloc[:, 0].values\n",
    "    y = portfolios_statistics.iloc[:, 1].values\n",
    "\n",
    "    # Construct a linear regression between mean and volatility\n",
    "    mean_volatility = LinearRegression()\n",
    "    mean_volatility.fit(x.reshape(-1, 1), y)\n",
    "    y_pred = mean_volatility.predict(x.reshape(-1, 1))\n",
    "    # slope = mean_volatility.coef_[0], intercept = mean_volatility.intercept_\n",
    "\n",
    "    # Plot the graph\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.scatter(x, y, alpha=0.6, label='data')\n",
    "    plt.plot(x, y_pred, color='green', linestyle='--', label='regression line')\n",
    "\n",
    "    plt.xlabel(portfolios_statistics.columns[0])\n",
    "    plt.ylabel(portfolios_statistics.columns[1])\n",
    "    plt.title(\"Mean-versus-Volatility Linear Regression\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # 2a. Use the model’s .score() method\n",
    "    r_squared = mean_volatility.score(x.reshape(-1, 1), y)\n",
    "    print(f\"R² of linear regression between mean and volatility: {r_squared:.4f}\")\n",
    "\n",
    "    # mean → X, VaR → Y\n",
    "    x = portfolios_statistics.iloc[:, 0].values\n",
    "    y = portfolios_statistics.iloc[:, 2].values\n",
    "\n",
    "    # Construct a linear regression between mean and VaR\n",
    "    mean_var = LinearRegression()\n",
    "    mean_var.fit(x.reshape(-1, 1), y)\n",
    "    y_pred = mean_var.predict(x.reshape(-1, 1))\n",
    "    # slope = mean_var.coef_[0], intercept = mean_var.intercept_\n",
    "\n",
    "    # Plot the graph\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.scatter(x, y, alpha=0.6, label='data')\n",
    "    plt.plot(x, y_pred, color='green', linestyle='--', label='regression line')\n",
    "\n",
    "    plt.xlabel(portfolios_statistics.columns[0])\n",
    "    plt.ylabel(portfolios_statistics.columns[1])\n",
    "    plt.title(\"Mean-versus-VaR Linear Regression\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # 2a. Use the model’s .score() method\n",
    "    r_squared = mean_var.score(x.reshape(-1, 1), y)\n",
    "    print(f\"R² linear regression between mean and VaR: {r_squared:.4f}\")\n",
    "\n",
    "    print(\"\\nCAPM\")\n",
    "    print(\"\"\"\\n1. For each of the n = 12 test assets, run the CAPM time-series regression:\n",
    "˜ ri t = αi +βi,mkt ˜ fmktt + ϵit(CAPM)\n",
    "So you are running 12 separate regressions, each using the T-sized sample of time-series data.\n",
    "2. Report the estimated βi,mkt, Treynor Ratio, αi, and Information Ratio for each of the n regres\n",
    "sions.\"\"\")\n",
    "\n",
    "    # Combine data from hedge_fund_series and merill_factors by date\n",
    "    combined_data = portfolios.join(factors[['MKT']], how='inner')\n",
    "\n",
    "    # These dictionaries will be later merged into a single dataframe\n",
    "    alpha_dict = {}\n",
    "    beta_dict = {}\n",
    "    treynor_ratio_dict = {}\n",
    "    info_ratio_dict = {}\n",
    "\n",
    "    for asset in portfolios.columns:\n",
    "        # pull out series of SPY and individual asset\n",
    "        X = combined_data['MKT']\n",
    "        y = combined_data[asset]\n",
    "\n",
    "        # add constant for intercept\n",
    "        X_const = sm.add_constant(X)\n",
    "\n",
    "        # run OLS: return_i = α + β·MKT + ε\n",
    "        model = sm.OLS(y, X_const).fit()\n",
    "\n",
    "        # extract the estimates\n",
    "        alpha = model.params['const']\n",
    "        beta = model.params['MKT']\n",
    "        residuals = model.resid\n",
    "\n",
    "        mean_return = y.mean()  # average monthly Agric return\n",
    "        tracking_error = residuals.std()  # sd of εt\n",
    "\n",
    "        # annualize mean and alpha by ×12, residual‐vol by √12\n",
    "        annualized_mean = mean_return * 12\n",
    "        annualized_alpha = alpha * 12\n",
    "        annualized_te = tracking_error * (12 ** 0.5)\n",
    "\n",
    "        # Calculate annualized treynor ratio and information ratio\n",
    "        annualized_treynor = annualized_mean / beta\n",
    "        annualized_info = annualized_alpha / annualized_te\n",
    "\n",
    "        # Append the statistics into the dictionaries\n",
    "        alpha_dict[asset] = annualized_alpha\n",
    "        beta_dict[asset] = beta\n",
    "        treynor_ratio_dict[asset] = annualized_treynor\n",
    "        info_ratio_dict[asset] = annualized_info\n",
    "\n",
    "    # Combine the dictionaries into one dataframe\n",
    "    capm_regression = pd.DataFrame({\n",
    "        'Alpha': pd.Series(alpha_dict),\n",
    "        'Market Beta': pd.Series(beta_dict),\n",
    "        'Treynor Ratio': pd.Series(treynor_ratio_dict),\n",
    "        'Information Ratio': pd.Series(info_ratio_dict)})\n",
    "\n",
    "    print(\"\\nCAPM Regression:\")\n",
    "    print(capm_regression)\n",
    "\n",
    "    print(\"\\n 3. If (CAPM)were true, what would be true of the Treynor Ratios, alphas, and Information Ratios?\")\n",
    "    print(\"\"\"If CAPM (asset return = beta * market return (assume 0 risk free rate)) were true, \n",
    "alpha is 0, treynor ratio = asset return / beta = market return, and information ratio =\n",
    "asset return / epsilon = 0 / epsilon = 0.\"\"\")\n",
    "\n",
    "    # sum the absolute alphas, then divide by the number of rows\n",
    "    annualized_mae = capm_regression['Alpha'].abs().sum() * 12 / len(capm_regression)\n",
    "    print(\"\\nMean absolute error:\", round(annualized_mae, 4))\n",
    "\n",
    "    print(\"\"\"\\nIf the pricing model worked, should these alpha estimates be large or small? Why? Based on\n",
    "your MAE stat, does this seem to support the pricing model or not?\n",
    "\\nIf the pricing model worked, alpha estimates should be small because in an ideal CAPM all asset returns \n",
    "are only depending on beta and market return, not alpha. MAE stat does not support the pricing model\n",
    "because MAE is large, meaning a discrepancy between the expected asset return as a proportion of\n",
    "market return and the actual asset return.\"\"\")\n",
    "\n",
    "    print(\"\\n 4 Amultifactor model\")\n",
    "    print(\"\"\"Let’s use regression methods to test whether the selected four pricing factors work.\n",
    "For each equity security, estimate the following regression to test the 4-factor model.\n",
    "For each regression, report the estimated α and r-squared.\"\"\")\n",
    "\n",
    "    combined_data = portfolios.join(factors[['MKT', 'SMB', 'HML', 'UMD']], how='inner')\n",
    "\n",
    "    # These dictionaries will be later merged into a single dataframe\n",
    "    alpha_dict = {}\n",
    "    r_square_dict = {}\n",
    "    adj_r_square_dict = {}\n",
    "\n",
    "    for asset in portfolios.columns:\n",
    "        X = combined_data[['MKT', 'SMB', 'HML', 'UMD']]\n",
    "        y = combined_data[asset]\n",
    "\n",
    "        X = sm.add_constant(X)  # now columns = ['const','MKT','SMB','HML','UMD']\n",
    "\n",
    "        # run OLS: return_i = α + β·MKT + ε\n",
    "        model = sm.OLS(y, X_const).fit()\n",
    "\n",
    "        # extract the estimates\n",
    "        alpha = model.params['const']\n",
    "        annualized_alpha = alpha * 12\n",
    "\n",
    "        # Raw coefficient of determination\n",
    "        r_squared = model.rsquared\n",
    "        # Adjusted R-squared penalizes for number of regressors\n",
    "        r_squared_adj = model.rsquared_adj\n",
    "\n",
    "        # Append the statistics into the dictionaries\n",
    "        alpha_dict[asset] = annualized_alpha\n",
    "        r_square_dict[asset] = r_squared\n",
    "        adj_r_square_dict[asset] = r_squared_adj\n",
    "\n",
    "    # Combine the dictionaries into one dataframe\n",
    "    multifactor_regression = pd.DataFrame({\n",
    "        'Alpha': pd.Series(alpha_dict),\n",
    "        'R-squared': pd.Series(r_square_dict),\n",
    "        'Adjusted R-squared': pd.Series(adj_r_square_dict)})\n",
    "    print(multifactor_regression)\n",
    "\n",
    "    # sum the absolute alphas, then divide by the number of rows\n",
    "    annualized_mae = multifactor_regression['Alpha'].abs().sum() * 12 / len(multifactor_regression)\n",
    "    print(\"\\nMean absolute error:\", round(annualized_mae, 4))\n",
    "\n",
    "    print(\"\"\"\\nIf the pricing model worked, should these alpha estimates be large or small? \n",
    "Why? Based on your MAE stat, does this seem to support the pricing model or not?\n",
    "\\nIf the pricing model worked, these alpha estimates should be small because asset returns\n",
    "would be fully explained by the four factors and alphas would be negligible. The MAE stats\n",
    "does not support this because a relatively large MAE indicates difference between returns \n",
    "estimated by the factor model and the actual return.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44257b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
